{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzN4mkk_ybqe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('blog_samples.csv')  # Ensure the CSV contains the 'text' column\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Initialize LLaMA 2 tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('meta-llama/LLaMA-2-7b')\n",
        "model = AutoModelForCausalLM.from_pretrained('meta-llama/LLaMA-2-7b')\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,                  # Adjust based on need\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "# Training\n",
        "trainer.train()\n",
        "trainer.save_model(\"llama_blog_generator\")  # Save the fine-tuned model\n",
        "tokenizer.save_pretrained(\"llama_blog_generator\")\n"
      ]
    }
  ]
}